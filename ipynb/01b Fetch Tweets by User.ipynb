{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Tweets by User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You must have [Python Twitter Tools](https://github.com/sixohsix/twitter) installed on the machine to run this script. You can install it by running the below cell (change the cell type in the toolbar above to `Code` instead of `Raw NBConvert`). You may need to use `\"! sudo easy_install twitter\"`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "! easy_install twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Style\n",
    "Let's make this thing look nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url(https://fonts.googleapis.com/css?family=Roboto+Slab:400,100);\n",
       "@import url(https://fonts.googleapis.com/css?family=Roboto+Mono:300);\n",
       "\n",
       "body{\n",
       "  font-family: \"Helvetica\", \"Helvetica Neue\", sans-serif;\n",
       "}\n",
       "\n",
       "#notebook {\n",
       "  font-size: 1.1em !important;\n",
       "  font-weight: 100;\n",
       "}\n",
       "\n",
       "a {\n",
       "\tcolor: #497285;\n",
       "}\n",
       "\n",
       "h1, h2, h3, h4, h5 {\n",
       "  font-family: \"Roboto Slab\", sans-serif;\n",
       "  font-weight: 100 !important;\n",
       "  font-size: 1.2 em;\n",
       "}\n",
       "\n",
       ".CodeMirror{\n",
       "  font-family: \"Roboto Mono\", monospace;\n",
       "  font-weight: 300;\n",
       "}\n",
       "\n",
       "div.prompt{\n",
       "  font-family: \"Roboto Mono\", monospace;\n",
       "  font-weight: 300;\n",
       "}\n",
       "\n",
       ".renderjson a              { text-decoration: none; }\n",
       ".renderjson .disclosure    { color: crimson;\n",
       "                             font-size: 150%; }\n",
       ".renderjson .syntax        { color: grey; }\n",
       ".renderjson .string        { color: black; }\n",
       ".renderjson .number        { color: #0CCA98; }\n",
       ".renderjson .boolean       { color: #5E366A; }\n",
       ".renderjson .key           { color: #497285; }\n",
       ".renderjson .keyword       { color: #2B4450; }\n",
       ".renderjson .object.syntax { color: #3FBAC2; }\n",
       ".renderjson .array.syntax  { color: #F78536; }\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "styles = open(\"../css/custom.css\", \"r\").read()\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the libraries we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twitter import *\n",
    "import csv, json\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Twitter Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the OAuth credentials needed below in [Twitter's application manager](https://apps.twitter.com/). Create a new app if you haven't already. After the app has been created, you'll find the necessary information under \"Keys and Access Tokens\". You may need to create access tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter OAuth Credentials\n",
    "consumer_key = '' # Consumer Key (API Key)\n",
    "consumer_secret = '' # Consumer Secret (API Secret)\n",
    "access_token = '' # Access Token\n",
    "access_secret = '' # Access Token Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = Twitter(auth=OAuth(access_token, access_secret, consumer_key, consumer_secret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Local Paths\n",
    "Paths on your machine to the file you'd like to save the tweets to.\n",
    "\n",
    "- _Example pickle, Mac: /Users/[username]/Documents/twitter-analysis/data/raw/tweets.p_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsonpath = '' # Path to the JSON file where retrieved tweets go\n",
    "picklepath = '' # Path to the pickle file where retrieved tweets go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whose Tweets?\n",
    "Whose tweets will we be getting? Write a list of usernames (also called screen names, Twitter handles and whatnot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usernames = ['UNICEFIndia','satyamevjayate','aamir_khan'] # Example: ['UNICEFIndia','satyamevjayate','UNICEF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle HTTP Errors\n",
    "This is from Matthew A. Russell's brilliant \"[Mining the Social Web, 2nd Edition (O'Reilly, 2013)](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%209%20-%20Twitter%20Cookbook.ipynb)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from urllib2 import URLError\n",
    "from httplib import BadStatusLine\n",
    "\n",
    "def make_twitter_request(t_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print >> sys.stderr, 'Too many retries. Quitting.'\n",
    "            raise e\n",
    "    \n",
    "        # See https://dev.twitter.com/docs/error-codes-responses for common codes\n",
    "    \n",
    "        if e.e.code == 401:\n",
    "            print >> sys.stderr, 'Encountered 401 Error (Not Authorized)'\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print >> sys.stderr, 'Encountered 404 Error (Not Found)'\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print >> sys.stderr, 'Encountered 429 Error (Rate Limit Exceeded)'\n",
    "            if sleep_when_rate_limited:\n",
    "                print >> sys.stderr, \"Retrying in 15 minutes...ZzZ...\"\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print >> sys.stderr, '...ZzZ...Awake now and trying again.'\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print >> sys.stderr, 'Encountered %i Error. Retrying in %i seconds' % \\\n",
    "                (e.e.code, wait_period)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return t_func(*args, **kw)\n",
    "        except api.TwitterHTTPError, e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError, e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print >> sys.stderr, 'URLError encountered. Continuing.'\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, 'Too many consecutive errors...bailing out.'\n",
    "                raise\n",
    "        except BadStatusLine, e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print >> sys.stderr, 'BadStatusLine encountered. Continuing.'\n",
    "            if error_count > max_errors:\n",
    "                print >> sys.stderr, 'Too many consecutive errors...bailing out.'\n",
    "                raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Retrieve User Tweets\n",
    "This is from Matthew A. Russell's brilliant \"[Mining the Social Web, 2nd Edition (O'Reilly, 2013)](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%209%20-%20Twitter%20Cookbook.ipynb)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_tweets(t, screen_name=None, user_id=None, max_results=1000):\n",
    "     \n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"    \n",
    "    \n",
    "    kw = {  # Keyword args for the Twitter API call\n",
    "        'count': 200,\n",
    "        'trim_user': 'false',\n",
    "        'include_rts' : 'true',\n",
    "        'since_id' : 1\n",
    "        }\n",
    "    \n",
    "    if screen_name:\n",
    "        kw['screen_name'] = screen_name\n",
    "    else:\n",
    "        kw['user_id'] = user_id\n",
    "        \n",
    "    max_pages = 16\n",
    "    results = []\n",
    "    \n",
    "    tweets = make_twitter_request(t.statuses.user_timeline, **kw)\n",
    "    \n",
    "    if tweets is None: # 401 (Not Authorized) - Need to bail out on loop entry\n",
    "        tweets = []\n",
    "        \n",
    "    results += tweets\n",
    "    \n",
    "    print('Fetched %i tweets from @%s...' % (len(tweets), screen_name))\n",
    "    \n",
    "    page_num = 1\n",
    "    \n",
    "    # Many Twitter accounts have fewer than 200 tweets so you don't want to enter\n",
    "    # the loop and waste a precious request if max_results = 200.\n",
    "    \n",
    "    # Note: Analogous optimizations could be applied inside the loop to try and \n",
    "    # save requests. e.g. Don't make a third request if you have 287 tweets out of \n",
    "    # a possible 400 tweets after your second request. Twitter does do some \n",
    "    # post-filtering on censored and deleted tweets out of batches of 'count', though,\n",
    "    # so you can't strictly check for the number of results being 200. You might get\n",
    "    # back 198, for example, and still have many more tweets to go. If you have the\n",
    "    # total number of tweets for an account (by GET /users/lookup/), then you could \n",
    "    # simply use this value as a guide.\n",
    "    \n",
    "    if max_results == kw['count']:\n",
    "        page_num = max_pages # Prevent loop entry\n",
    "    \n",
    "    while page_num < max_pages and len(tweets) > 0 and len(results) < max_results:\n",
    "    \n",
    "        # Necessary for traversing the timeline in Twitter's v1.1 API:\n",
    "        # get the next query's max-id parameter to pass in.\n",
    "        # See https://dev.twitter.com/docs/working-with-timelines.\n",
    "        kw['max_id'] = min([ tweet['id'] for tweet in tweets]) - 1 \n",
    "    \n",
    "        tweets = make_twitter_request(t.statuses.user_timeline, **kw)\n",
    "        results += tweets\n",
    "\n",
    "        print('Fetched %i tweets from @%s...' % (len(tweets), screen_name))\n",
    "    \n",
    "        page_num += 1\n",
    "        \n",
    "    print('Done! We fetched %i tweets from @%s' % (len(results), screen_name))\n",
    "\n",
    "    return results[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Fetched 200 tweets from @UNICEFIndia...\n",
      "Done! We fetched 3200 tweets from @UNICEFIndia\n",
      "Fetched 200 tweets from @satyamevjayate...\n",
      "Fetched 198 tweets from @satyamevjayate...\n",
      "Fetched 199 tweets from @satyamevjayate...\n",
      "Fetched 195 tweets from @satyamevjayate...\n",
      "Fetched 199 tweets from @satyamevjayate...\n",
      "Fetched 198 tweets from @satyamevjayate...\n",
      "Fetched 199 tweets from @satyamevjayate...\n",
      "Fetched 200 tweets from @satyamevjayate...\n",
      "Fetched 199 tweets from @satyamevjayate...\n",
      "Fetched 200 tweets from @satyamevjayate...\n",
      "Fetched 200 tweets from @satyamevjayate...\n",
      "Fetched 200 tweets from @satyamevjayate...\n",
      "Fetched 199 tweets from @satyamevjayate...\n",
      "Fetched 194 tweets from @satyamevjayate...\n",
      "Fetched 198 tweets from @satyamevjayate...\n",
      "Fetched 196 tweets from @satyamevjayate...\n",
      "Done! We fetched 3174 tweets from @satyamevjayate\n",
      "Fetched 200 tweets from @aamir_khan...\n",
      "Fetched 153 tweets from @aamir_khan...\n",
      "Fetched 0 tweets from @aamir_khan...\n",
      "Done! We fetched 353 tweets from @aamir_khan\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for username in usernames:\n",
    "    try:\n",
    "        data = get_user_tweets(t, screen_name=username, max_results=3200)\n",
    "        for status in data:\n",
    "            tweets.append(status)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6727"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(jsonpath, 'wb') as tweetsfile: # Get ready to write to output file\n",
    "    json.dump(tweets, tweetsfile) # Write tweets to json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(picklepath, \"wb\") as tweetsfile:\n",
    "    pickle.dump(tweets, tweetsfile) # Write tweets to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
